comp <- data$Column
# Use different functions to find the summary statistics of the compensation data
length(comp)
mean(comp)
median(comp)
min(comp)
max(comp)
var(comp)
sd(comp)
summary(comp)
# Find the number of compensations that are equal to, greater than equal to, and less than $5 Million
sum(comp == 5)
sum(comp >= 5)
sum(comp < 5)
# Find the proportion of compensations that are equal to $5 Million
sum(comp ==5)/length(comp)
# Draw the histogram of the compensation data
hist(comp, breaks = 500)
# Report the frequency of different values in the compensation data
table(comp)
data = data.frame('Column' = c(1,2,3,4,5,6))
comp <- data$Column
# Use different functions to find the summary statistics of the compensation data
length(comp)
mean(comp)
median(comp)
min(comp)
max(comp)
var(comp)
sd(comp)
summary(comp)
# Find the number of compensations that are equal to, greater than equal to, and less than $5 Million
sum(comp == 5)
sum(comp >= 5)
sum(comp < 5)
# Find the proportion of compensations that are equal to $5 Million
sum(comp ==5)/length(comp)
# Report the frequency of different values in the compensation data
table(comp)
#To read the given dataset
library(readxl)
#data <- read_excel(file.choose(),sheet=2) #for excel
data <- read.csv(file.choose(),sheet2) #for csv, use sheet=2 only if data is in second sheet.
#To read the given dataset
library(readxl)
data <- read_excel(file.choose(),sheet=2) #for excel
#To read the given dataset
library(readxl)
data <- read_excel(file.choose()) #for excel
#data <- read.csv(file.choose(),sheet2) #for csv, use sheet=2 only if data is in second sheet.
comp <- data$Column
# Use different functions to find the summary statistics of the compensation data
length(comp)
mean(comp)
median(comp)
min(comp)
max(comp)
var(comp)
pnorm(1,0.96,0.25)
sqrt(1.7*(1-1.7)/2250)
sqrt((1.7*(1-1.7))/2250))
sqrt((1.7*(1-1.7))/2250)
pnorm(7550,9248.846,1693.437,lower.tail = F)
pnorm(10,8.093,0.953,lower.tail = F)
pnorm(1210,570,125)
pnorm(1210,570,125,lower.tail = F)
pnorm(350,-383,33)
pnorm(-350,-383,33.938)
pnorm(2)
pnorm(-2)
1-pnorm(2)
1-pnorm(350,383,33.938)
library(readxl)
data.car <- read_excel(file.choose(), range = "A1:B101", col_names = TRUE)
car.model <- lm(PRI ~ INC, data = data.car)
# Summary of regression output
summary(car.model)
a <- 0.01
confint(car.model, level = 1-a)
a <- 0.05
confint(car.model, level = 1-a)
df.forecast <- data.frame("INC" = c(80000))
# Make forecasts for the values in the dataframe
forecasts <- predict(car.model, newdata = df.forecast, interval = "prediction", level = 1-a)
(forecasts[,"fit"] - forecasts[,"lwr"]
(forecasts[,"fit"] - forecasts[,"lwr"])
(forecasts[,"fit"] - forecasts[,"lwr"])
(forecasts[,"fit"] - forecasts[,"lwr"])/2
4.68/sqrt(1414)
pnorm(6.30,6.19,0.1244,lower.tail = F)
(6.30-6.19)/0.1244575
1 - pnorm(0.8838)
pnorm(0.8838)
(6.30-6.19)/0.1244575
pnorm(-0.811)
sqrt(291(1-291)/5001)
sqrt(291*(1-291)/5001)
data.train <- read.csv(file.choose())
data.test <- read.csv(file.choose())
t.test(data.train$FARE[data.train$PAX >= 10000], alternative = "greater", mu = 200)
t.test(data.train$FARE[data.train$PAX >= 10000], alternative = "greater", mu = 150)
n.popular <- length(data.train$FARE[data.train$PAX >= 10000])
xbar <- mean(data.train$FARE[data.train$PAX >= 10000])
se.xbar <- sd(data.train$FARE[data.train$PAX >= 10000])/sqrt(n.popular)
t.stat2 <- (xbar - 200)/se.xbar
p.value2 <- 1 - pnorm(t.stat2)
(1-pnorm(abs(t.stat)))
n.vac <- length(data.train$FARE[data.train$VACATION == "Yes"])
n.novac <- length(data.train$FARE[data.train$VACATION == "No"])
delta <- mean(data.train$FARE[data.train$VACATION == "Yes"]) - mean(data.train$FARE[data.train$VACATION == "No"])
s.delta <- sqrt((sd(data.train$FARE[data.train$VACATION == "Yes"]))^2/n.vac + (sd(data.train$FARE[data.train$VACATION == "No"]))^2/n.novac)
t.stat1 <- delta/s.delta
p.value1 <- 2*(1-pnorm(abs(t.stat)))
##########################################
n.vac <- length(data.train$FARE[data.train$VACATION == "Yes"])
n.novac <- length(data.train$FARE[data.train$VACATION == "No"])
delta <- mean(data.train$FARE[data.train$VACATION == "Yes"]) - mean(data.train$FARE[data.train$VACATION == "No"])
s.delta <- sqrt((sd(data.train$FARE[data.train$VACATION == "Yes"]))^2/n.vac + (sd(data.train$FARE[data.train$VACATION == "No"]))^2/n.novac)
t.stat1 <- delta/s.delta
p.value1 <- 2*(1-pnorm(abs(t.stat1)))
t.test(data.train$FARE[data.train$VACATION == "Yes"], data.train$FARE[data.train$VACATION == "No"], alternative = "two.sided")
5/sqrt(4)
25/4
qnorm(1-0.05/2)
qnorm(1-0.01/2)
qnorm(1-0.3/2)
qnorm(1-0.03/2)
qnorm(1-0.03/2)
1 - pnorm(5)
1 - pnorm(-5)
1 - pnorm(abs(-5)
)
3.065
3.065+3*0.093
3.065-3*0.093
3.344-2.786
3.344-2.786/3
(3.344-2.786)/3
680.804 - 2*25.699
680.804 + 2*25.699
pnorm(629,680.084,25.699, lower.tail = FALSE)
pnorm(629,680.084,25.699, lower.tail = True)
pnorm(629,680.084,25.699, lower.tail = TRUE)
pnorm(1020,987.304,32.664)
pnorm(1020,987.304,32.664, lower.tail = FALSE)
(36.481 â€“ 44.842)/sqrt( 11.788^2 + 11.817^2)
(36.481-44.842)/sqrt( 11.788^2 + 11.817^2)
1 - pnorm(abs(-0.5009206))
(1-0.3082135)*100
pnorm(0.5009206)
2*1.672
0.505*(-10) + 1.672
-0.505*(-10) + 1.672
-0.505*(-10) - 1.672
1 - 0.003
33.179*1000
pnorm(35825,33179,2459,lower.tail = FALSE)
0.14*100
pnorm(35.825,33.179,2.459)
pnorm(35.825,33.179,2.459,lower.tail = F)
33179+2459
pnorm(44000,50429,6299,lower.tail = FALSE)
38/95
data = read_excel(file.choose(),sheet=5)
View(data)
View(data)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
View(model1)
View(data)
View(data)
View(data)
route1 = data[data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE==580 & data$PAX==3500 ]]
View(route1)
route1 = data[data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ]]
data$DISTANCE = as.numeric(data$DISTANCE)
data$PAX = as.numeric(data$PAX)
route1 = data[data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ]]
route1 = data(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
route1 = data(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
route1 = data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ]
route1
P = mean(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
n = len(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
P = mean(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
n = length(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
std = sd(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
100-98
1-0.98
a = 0.02
ul = P + qnorm(1-a/2) * (std/sqrt(n))
ll = P - qnorm(1-a/2) * (std/sqrt(n))
P = mean(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE==580 & data$PAX==3500 ])
P = mean(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE==580 & data$PAX==3500 ])
n = length(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
std = sd(data$FARE[data$VACATION=='Yes' & data$SWA=='No' & data$DISTANCE>580 & data$PAX>3500 ])
[ll,ul]
ll
ul
test = data.frame('SWA'=c('No'),'DISTANCE'=c(580),'VACATION'=c('No'),'PAX'=c(3500))
View(test)
test = data.frame('SWA'=c('No','Yes'),'DISTANCE'=c(580,900),'VACATION'=c('Yes','No'),'PAX'=c(3500,10000))
View(test)
forecast = predict(model1,data=test,interval = "prediction", level = 0.98)
View(forecast)
test = data.frame('SWA'=c('No','Yes'),'DISTANCE'=c(580,900),'VACATION'=c('Yes','No'),'PAX'=c(3500,10000))
forecast = predict(model1,data=test, interval = "prediction", level = 0.98)
View(test)
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
summary(forecast)
forecast
data$SWA <- ifelse(data$SWA=="Yes", 1, 0)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
data$SWA <- ifelse(data$SWA=="Yes", 1, 0)
data$VACATION <- ifelse(data$VACATION=="Yes", 1, 0)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
data$DISTANCE = as.numeric(data$DISTANCE)
data$PAX = as.numeric(data$PAX)
test = data.frame('SWA'=c('No','Yes'),'DISTANCE'=c(580,900),'VACATION'=c('Yes','No'),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction
forecast
forecast
summary(model1)
View(data)
data = read_excel(file.choose(),sheet=5)
View(data)
data$SWA <- ifelse(data$SWA=="Yes", 1, 0)
View(data)
data$VACATION <- ifelse(data$VACATION=="Yes", 1, 0)
View(data)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
test = data.frame('SWA'=c('No','Yes'),'DISTANCE'=c(580,900),'VACATION'=c('Yes','No'),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
View(data)
test = data.frame('SWA'=c('0','1'),'DISTANCE'=c(580,900),'VACATION'=c('1','0'),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
data$DISTANCE = as.numeric(data$DISTANCE)
data$PAX = as.numeric(data$PAX)
test = data.frame('SWA'=c('0','1'),'DISTANCE'=c(580,900),'VACATION'=c('1','0'),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
View(data)
data = read_excel(file.choose(),sheet=5)
data$DISTANCE = as.numeric(data$DISTANCE)
data$PAX = as.numeric(data$PAX)
data$SWA <- ifelse(data$SWA=="Yes", 1, 0)
data$VACATION <- ifelse(data$VACATION=="Yes", 1, 0)
model1 = lm(FARE~PAX+DISTANCE+VACATION+SWA, data=data)
summary(model1)
test = data.frame('SWA'=c('0','1'),'DISTANCE'=c(580,900),'VACATION'=c('1','0'),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
test = data.frame('SWA'=c(0,1),'DISTANCE'=c(580,900),'VACATION'=c(1,0),'PAX'=c(3500,10000))
forecast = predict(model1,newdata=test, interval = "prediction", level = 0.98)
forecast
EB = (221-866 - 125.9419)/qnorm(1-0.02/2)
EA = (211-01216 - 114.9424)/qnorm(1-0.02/2)
TSTAT = delta/ sqrt(EB^2 + EA^2)
delta = 114.9424 - 125.9419
EB = (221-866 - 125.9419)/qnorm(1-0.02/2)
EA = (211-01216 - 114.9424)/qnorm(1-0.02/2)
TSTAT = delta/ sqrt(EB^2 + EA^2)
p = 1 - pnorm(abs(TSTAT))
pVALUE = 1 - pnorm(abs(TSTAT))
1 - 0.49
data2 = read_excel(file.choose(),sheet=4)
View(data2)
data2 = read_excel(file.choose(),sheet=4,range = "A3:C3")
View(data2)
data2 = read_excel(file.choose(),sheet=4)
View(data2)
View(data2)
mean(data2)
mean(data2$SP)
sd(data2$SP)
mean(data2$LULU)
sd(data2$LULU)
View(data2)
model2 = lm(LULU~SP,data=data2)
summary(model2)
t.test(data2$LULU[data.train$LULU > 0], alternative = "greater", mu = 0)
t.tesT(data2$LULU[data2$LULU > 0], alternative = "greater", mu = 0)
t.test(data2$LULU[data2$LULU > 0], alternative = "greater", mu = 0)
1 - 2.2e-16
View(model2)
x = mean(data[data$FARE[data$SWA==0]])
x = mean([data$FARE[data$SWA==0]])
x = mean([data$FARE[data$SWA==0])
x = mean(data$FARE[data$SWA==0])
s = sd(data$FARE[data$SWA==0])
pnorm(70,x,s,lower.tail = F)
1 - (38/95)
t.test(38/95, 1-(38/95) , alternative = "two.sided")
x = c(1,2,3,"hello")
x
typeof(x)
123sathish = 'sad'
a = [1,2,3,4,5]
a = c(1,2,3,4,5)
b = c(1,2,3,4,5,6,7,8,9,10)
a + b
b + a
d = c(1,2,3)
a + d
### The first part introduces how to make basic operations, discuss different types of data,
### and how to manipulate vectors and matrices.
### The second part takes a data set to illustrate how to open the data, plot different graphs, and
### to run a linear regression.
###
### Part I:
###
### At its most basic level R is just a fancy calculator (e.g., *,/,+,-)
### Everything is based on assigning names.
### The symbol "<-" (assign) works as "="
x <- 2
### this creates a (numeric) variable x and assign 2 to it.
### we can see the value stored in x by typing x
x
### note that R is case sensitive so that X will not give you the same value.
### As mentioned R is a calculator. Thus assigning a variable named "testvar" the value 4+12 can be done as
testvar <- 4+12
### testvar stored the value 4+12=16.
### To inspect a variable just type the name of it
testvar
### The first part introduces how to make basic operations, discuss different types of data,
### and how to manipulate vectors and matrices.
### The second part takes a data set to illustrate how to open the data, plot different graphs, and
### to run a linear regression.
###
### Part I:
###
### At its most basic level R is just a fancy calculator (e.g., *,/,+,-)
### Everything is based on assigning names.
### The symbol "<-" (assign) works as "="
x <- 2
### this creates a (numeric) variable x and assign 2 to it.
### we can see the value stored in x by typing x
x
### note that R is case sensitive so that X will not give you the same value.
### As mentioned R is a calculator. Thus assigning a variable named "testvar" the value 4+12 can be done as
testvar <- 4+12
### testvar stored the value 4+12=16.
### To inspect a variable just type the name of it
testvar
### making calculations is easy. Square root is the command sqrt
sqrt(testvar)
### For "help". When in doubt about a command type ? before the command (e.g. ?sqrt)
### An explanation will be displayed (if the command is recognized by R)
?sqrt
?sqrt
??sqrt
testvector <- c(10,3,5,6,8)
mean(testvector)
sd(testvector)
summary(testvector)
testvector^2
5*testvector+7
vec1 <- c(8, 5.6, 9, 10.1)
vec2 <- c(7, 9, 11, 34)
vec1 + vec2
(vec1 * vec2) + 5
testvector[3]
testvector[2] <- 0
testvector
vector <- c (testvector, testvector)
vector
ComponentAboveSeven <- testvector > 7
ComponentAboveSeven
NewVector <- testvector[ ComponentAboveSeven ]
Indices <- c(1,5)
AnotherNewVector <-  testvector[Indices]
AnotherNewVector
v1 <- testvector
v2 <- sqrt(testvector)
v3 <- 4 + 2*testvector
examplematrix <- matrix(data = c(v1, v2, v3 ), ncol=3, nrow=5)
examplematrix
nrow(examplematrix)
ncol(examplematrix)
t(examplematrix)
x0 <- c(0,0,0,0,0,0,0,0,0,0)
### or
x0 <- rep(0,times=10)
xa <- 1:10
xb <- seq.int(from=1, to=10, by=1)
xc <- c(1,2,3,4,5,6,7,8,9,10)
length(xa)
### we can square a vector
ya <- xa^2
ya
plot (xa, ya)
plot (xa, ya, xlab = "X label", ylab = "Y label", col="blue", main="Plot Example")
points(xa, 10*sqrt(xa),col="red")
lines(xa, 10*sqrt(xa),col="red")
Numeric <- c(3,3.141592,7,9)
xNumeric <- c(3,3.141592,7,9)
xLogical <- c(TRUE,FALSE,TRUE,TRUE)
xCharacters <- c("fuqua","data mining","analytics","fuqua")
xMixed <- c(3,TRUE,1,"Regression")
summary(xNumeric)
summary(xLogical)
summary(xCharacters)
xNumeric[1]+1
xMixed[1]+1
as.numeric(xMixed[1])+1
as.character(xNumeric)
### the function as() allows you to convert between many types.
### This is important as some functions require specific data format as input (which require us to convert them before calling the function)
### The functino str() (str stands for structure) tells you which type a particular variable is
str(xNumeric)
str(xLogical)
str(xCharacters)
vector_colors <- c("blue","red", "white", "blue", "green","red", "red","blue","blue", "blue","white")
summary(vector_colors)
factor_colors <-factor(vector_colors)
summary(vector_colors)
summary(factor_colors)
plot(factor_colors)
plot(factor_colors, xlab="Colors", ylab="Frequency", main="Use of Colors", col=levels(factor_colors))
df <- data.frame(xNumeric, xLogical, xCharacters)
summary(df)
names(df)
df[3,2]
df[3,2]
df <- data.frame(xNumeric, xLogical, xCharacters)
### lets see its summary
summary(df)
### we can get the names of each column with
names(df)
df[3,2]
df[,1]
df[3,]
which(df$xNumeric > 5)
dftest <- df
df[,1:2]
df[,-2]
df[, names(df) %in% c("xNumeric","xCharacters" ) ]
df[, !( names(df) %in% c("xLogical") )]
getwd()
oj <- read.csv("oj_PreAssignment.csv")
setwd('/Users/sathish/Documents/Github/Data-Science-for-Business/Pre - Assignment')
getwd()
oj <- read.csv("oj_PreAssignment.csv")
View(oj)
source("DataAnalyticsFunctions.R")
installpkg("lattice")
library(lattice)
installpkg("KernSmooth")
library(KernSmooth)
load("WorkspacePreAssigOnlineTest.RData")
source("DataAnalyticsFunctions.R")
installpkg("lattice")
library(lattice)
installpkg("KernSmooth")
library(KernSmooth)
load("WorkspacePreAssigOnlineTest.RData")
#a)
mean(germancredit$amount)
#b)
median(germancredit$amount)
#c)
summary(germancredit$amount)
#d)  # note that "View" has the first line uppercase
View(germancredit)
View(germancredit)
mean(germancredit$amount[germancredit$amount > 1] )
#b)
mean(germancredit$amount[germancredit$duration > 12] )
#c)
mean(germancredit$amount[germancredit$duration <= 12] )
#d)
mean(germancredit$amount[germancredit$duration == 1] )
par(mfrow=c(1,2))
hist(germancredit$amount, xlab="Amount (DB)",main="Loan Amounts")
hist(germancredit$duration, xlab="Duration (months)", main="Loan Duration")
par(mfrow=c(1,1))
#b)
par(mfrow=c(1,2))
boxplot(germancredit$amount, ylab="Amount of Loan (DB)")
boxplot(germancredit$duration, ylab="Duration of Loan (months)")
par(mfrow=c(1,1))
plot(germancredit$duration, germancredit$amount, xlab="Duration (months)", ylab="Amount (DB)")
smoothScatter(germancredit$duration, germancredit$amount, xlab="Duration (months)", ylab="Amount (DB)")
lines(lowess(germancredit$duration, germancredit$amount),col="blue",lwd=2,lty=2)
reg <- glm( amount ~ duration + history , data = germancredit)
coef(reg)
reg <- glm( amount ~ duration + history , data = germancredit)
summary(reg)$coef[,3] < 0.05
reg <- glm( amount ~ duration + history , data = germancredit)
which( summary(reg)$coef[,4] < 0.05 )
summary(reg)
summary(reg)$coef[1]
summary(reg)$coef[4]
summary(reg)$coef[3]
summary(reg)$coef[,3]
summary(reg)$coef[,4]
aggregate(Default ~ history, data=germancredit,FUN=mean)
reg <- glm (Default ~ history, data=germancredit)
summary(reg)
aggregate(duration ~ history, data=germancredit,FUN=mean)
aggregate(amount ~ history, data=germancredit,FUN=mean)
aggregate(Default ~ history, data=germancredit,FUN=mean)
plot( aggregate(Default ~ history, data=germancredit,FUN=mean),   ylab="Default rate",xlab="Credit history")
plot( factor(Default) ~ history, data=germancredit, col=c(8,2),  ylab="Default",xlab="Credit history")
plot( germancredit$Default, germancredit$history, xlab="Default (0 or 1)", ylab = "Credit history")
plot( factor(Default) ~ history, data=germancredit, col=c(8,2),  ylab="Default",xlab="Credit history")
